## Folder description
Performance metrics for each method evaluated in the study.

## Files documentation
- [catboost:](catboost) Performance metrics for CatBoost object detection, generated by `eval_pipeline.py`.  
- [filter:](filter) Performance metrics for structural alerts, generated by `eval_pipeline.py`.  
- [isoforest:](isoforest) Performance metrics for Isolation Forest, generated by `eval_pipeline.py`.  
- [vae:](vae) Performance metrics for the Variational Autoencoder for Anomaly Detection, generated by `eval_pipeline.py`.  
- [score:](score) Performance metrics for primary HTS readout ranking, generated by `eval_pipeline.py`.  
- [mvsa:](mvsa) Performance metrics for MVS-A, generated by `eval_pipeline.py`.  
- [fp_detectors:](fp_detectors) Performance metrics for Hit Dexter, SCAM Detective and the autofluorescence predictor.  
- [summary:](summary) Average metrics across replicates for each approach and p-values of statistical tests.  
- [case_study_fn.csv:](case_study_fn.csv) MVS-A ranking of inactive compounds for the HTS case study.  
- [case_study_tp.csv:](case_study_fp.csv) MVS-A ranking of active compounds for the HTS case study.  

